{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d03de6e-99df-4e85-9382-2d4a7a319c1a",
   "metadata": {},
   "source": [
    "## 퍼셉트론\n",
    "* 인간의 뇌는 치밀하게 연결된 뉴런 약 1,000억 개로 이루어져 있습니다. \n",
    "* 뉴런과 뉴런 사이에는 시냅스라는 연결 부위가 있는데, 신경 말단에서 자극을 받으면 시냅스에서 화학 물질이 나와 전위 변화를 일으킵니다. \n",
    "* 전위가 임계 값을 넘으면 다음 뉴런으로 신호를 전달하고, 임계 값에 미치지 못하면 아무것도 하지 않습니다. \n",
    "* 회로는 입력 값을 놓고 활성화 함수에 의해 일정한 수준을 넘으면 참을, 그렇지 않으면 거짓을 내보내는 일을 하는데 뉴런과 유사합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c39d5b-e42e-4244-b756-7d342ce7a4f1",
   "metadata": {},
   "source": [
    "## 인공신경망\n",
    "* 시작은 ‘켜고 끄는 기능이 있는 신경’을 그물망 형태로 연결하면 사람의 뇌처럼 동작할 수 있다는 가능성을 처음으로 주장한 맥컬럭-월터 피츠(McCulloch-Walter Pitts)의 1943년 논문 발표\n",
    "* 1957년, 미국의 신경 생물학자 프랑크 로젠블랫(Frank Rosenblatt)이 이 개념을 실제 장치로 만들어 선보입니다 - 퍼셉트론\n",
    "    + 퍼셉트론은 입력 값을 여러 개 받아 출력을 만드는데, \n",
    "    + 이때 입력 값에 가중치를 조절할 수 있게 만들어 최초로 ‘학습’을 하게 했습니다\n",
    "* 3년 후, 경사 하강법을 도입해 최적의 경계선을 그릴 수 있게 한 아달라인(Adaline)이 개발    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a270cfa-37b9-435f-af2d-48a50ed1eb5a",
   "metadata": {},
   "source": [
    "## 퍼셉트론의 한계\n",
    "* 퍼셉트론이나 아달라인은 모두 2차원 평면상에 직선을 긋는 것만 가능합니다.\n",
    "* 선을 여러 개 아무리 그어 보아도 하나의 직선으로는 흰색 점과 검은색 점을 구분할 수 없는 상황 발생\n",
    "    + 퍼셉트론의 한계를 설명할 때 등장하는 XOR(exclusive OR) 문제\n",
    "    + 인공지능 분야의 선구자였던 MIT의 마빈 민스키(Marvin Minsky) 교수가 1969년에 발표한 “퍼셉트론즈(Perceptrons)”라는 논문에 나오는 내용\n",
    "    + 이 논문 이후 인공지능 연구가 한동안 침체기를 겪게 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f27dc4-f7eb-4705-8fc2-e4bceaa384f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])  # 가중치\n",
    "    b = -0.5                  # 편향\n",
    "    val = 0                   # 출력값\n",
    "    # sum = x1*w1 + x2*w2 + b\n",
    "    sum = np.sum(x * w) + b   # 행렬을 사용하면 식이 간단\n",
    "\n",
    "    if sum > 0: val = 1       # 0보다 크면 1로 출력\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1ea7e8-f73b-4e64-a802-d48bd386a2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 AND 0 =  0\n",
      "0 AND 1 =  0\n",
      "1 AND 0 =  0\n",
      "1 AND 1 =  1\n"
     ]
    }
   ],
   "source": [
    "print('0 AND 0 = ', AND(0,0))\n",
    "print('0 AND 1 = ', AND(0,1))\n",
    "print('1 AND 0 = ', AND(1,0))\n",
    "print('1 AND 1 = ', AND(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746fd774-482b-4d90-a330-0422b96193b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])  # 가중치\n",
    "    b = -0.3                 # 편향\n",
    "    val = 0                   # 출력값\n",
    "    sum = np.sum(x * w) + b   # 행렬을 사용하면 식이 간단\n",
    "\n",
    "    if sum > 0: val = 1       # 0보다 크면 1로 출력\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3a918c-350c-4d01-8042-7f294e69cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 OR 0 =  0\n",
      "0 OR 1 =  1\n",
      "1 OR 0 =  1\n",
      "1 OR 1 =  1\n"
     ]
    }
   ],
   "source": [
    "print('0 OR 0 = ', OR(0,0))\n",
    "print('0 OR 1 = ', OR(0,1))\n",
    "print('1 OR 0 = ', OR(1,0))\n",
    "print('1 OR 1 = ', OR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b73bc-7110-4f62-98b6-7cc88d08508f",
   "metadata": {},
   "source": [
    "## 다층 퍼셉트론(multilayer perceptron)\n",
    "* 퍼셉트론 두 개를 각각 처리하는 은닉층(hidden layer)을 만듭\n",
    "    + x1과 x2를 두 연산으로 각각 보냅니다. \n",
    "        * 각 값에 가중치(w)를 곱하고 바이어스(b)를 더해 은닉층으로 전송\n",
    "    + 첫 번째 연산에서는 NAND 처리를 합니다 - 결괏값 1 \n",
    "    + 이와 동시에 두 번째 연산에서 OR 처리를 합니다. - 결괏값 2\n",
    "    + 결괏값 1과 결괏값 2를 가지고 AND 처리\n",
    "* 다층 퍼셉트론을 사용할 경우 XOR 문제는 해결되었지만, 은닉층에 포함된 가중치를 업데이트할 방법이 없었던 것\n",
    "    + 다층 퍼셉트론의 적절한 학습 방법을 찾기까지 그 후로 약 20여 년의 시간이 더 필요\n",
    "    + 인공지능의 겨울\n",
    "* 최적화된 예측선을 잘 그려 주던 아달라인을 발전시켜 SVM이나 로지스틱 회귀 모델을 만든 그룹\n",
    "* 여러 어려움 속에서도 끝까지 다층 퍼셉트론의 학습 방법을 찾던 그룹으로 나뉨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daae3b71-a071-4700-9634-418c4ae0b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-0.5, -0.5])  # NAND는 가중치를 음수로\n",
    "    b = 0.7                     # 편향은 양수로\n",
    "    val = 0\n",
    "    sum = np.sum(x * w) + b\n",
    "\n",
    "    if sum > 0: val = 1\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034205d3-5aee-4d67-90fe-4134bd73dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 NAND 0 =  1\n",
      "0 NAND 1 =  1\n",
      "1 NAND 0 =  1\n",
      "1 NAND 1 =  0\n"
     ]
    }
   ],
   "source": [
    "print('0 NAND 0 = ', NAND(0,0))\n",
    "print('0 NAND 1 = ', NAND(0,1))\n",
    "print('1 NAND 0 = ', NAND(1,0))\n",
    "print('1 NAND 1 = ', NAND(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516f09da-2abc-44db-bea5-48830d746048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(x1, x2):\n",
    "    p1 = NAND(x1, x2)\n",
    "    p2 = OR(x1, x2)\n",
    "    val = AND(p1, p2)\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769a2260-0378-4bfb-8626-dc2d893e1dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XOR 0 =  0\n",
      "0 XOR 1 =  1\n",
      "1 XOR 0 =  1\n",
      "1 XOR 1 =  0\n"
     ]
    }
   ],
   "source": [
    "print('0 XOR 0 = ', XOR(0,0))\n",
    "print('0 XOR 1 = ', XOR(0,1))\n",
    "print('1 XOR 0 = ', XOR(1,0))\n",
    "print('1 XOR 1 = ', XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9739ce6-1e36-4367-8b2b-826841289e02",
   "metadata": {},
   "source": [
    "### 신경망 작동원리 파악\n",
    "* 지금까지 수작업으로 다층 퍼셉트론에 전달되는 값에\n",
    "* 대한 결과값을 계산하였음\n",
    "* 한편, 복잡하게 구성되는 다층 퍼셉트론에서는 이러한 수작업은 불가능에 가까움\n",
    "* 수 많은 계층과 노드들을 가지는 복잡한 신경망의 계산은\n",
    "* 매우 간결하게 출력값을 구할 수 있는 수학적 방법이 필요\n",
    "    + => 간결한 접근 방법을 제공하는 것 : 행렬(벡터) 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729066a5-a772-4db8-a63b-6adb844746eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05, 0.6 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력값과 가중치\n",
    "X = np.array([1.0, 0.5])\n",
    "W = np.array([[0.9, 0.2],\n",
    "              [0.3, 0.8]])\n",
    "\n",
    "Y = np.dot(X, W)  # 행렬 곱연산 (내적)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a6c85a-2664-41d3-b73a-c3fb42f8ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값이 0.5이상이면 1로, 그렇치 않으면 0으로 출력\n",
    "def sigmoid(x):\n",
    "    try:\n",
    "        # 입력값이 행렬이라면\n",
    "        for i in range(0, len(x)):\n",
    "            x[i] = 1 / (1 + np.e ** -x[i])\n",
    "    except:\n",
    "        # 입력값이 단일값이라면\n",
    "        x = 1 / (1 + np.e ** -x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "150ab8d4-45a5-42cf-bdcb-8bee6540998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7407749 , 0.64565631])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f8ec8b-6a3c-4446-affc-9f7b2e468ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.16 0.42 0.62]\n",
      "[0.76133271 0.60348325 0.65021855]\n",
      "[0.97594736 0.88858496 1.25461119]\n",
      "[0.72630335 0.70859807 0.77809706]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([0.9,0.1,0.8])\n",
    "W1 = np.array([[0.9,0.3,0.4],\n",
    "               [0.2,0.8,0.2],\n",
    "               [0.1,0.5,0.6]])\n",
    "W2 = np.array([[0.3,0.7,0.5],\n",
    "               [0.6,0.5,0.2],\n",
    "               [0.8,0.1,0.9]])\n",
    "\n",
    "Y1 = np.dot(W1, X) # 입력층에서 은닉층 순전파\n",
    "print(Y1)\n",
    "print(sigmoid(Y1))\n",
    "\n",
    "Y2 = np.dot(W2, Y1) # 은닉층에서 출력층 순전파\n",
    "print(Y2)\n",
    "print(sigmoid(Y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87444c2-0e61-479d-baca-88cd1822b29b",
   "metadata": {},
   "source": [
    "## 오차 역전파(back propagation)\n",
    "* 1986년에 힌튼 교수 발표\n",
    "* 신경망의 각 노드가 가지고 있는 가중치(Weight)와 편향(Bias)을 학습시키기 위한 알고리즘\n",
    "* 신경망의 입력층부터 출력층까지 순서대로 입력값,가중치,편향들을 계산하고 저장하는 것을 순전파라 함\n",
    "* 신경망의 예측값 정확도를 높이기 위해 출력값과 실제 예측하고자 하는 값을 비교하여 \n",
    "  오차를 확인하고 출력층에서 입력층으로 나아가며 가중치를 변경하는 것은 역전파라 함\n",
    "* 하지만, 활성화 함수로 사용된 시그모이드 함수로 인한 기울기 소실 문제 발생\n",
    "    + 제프리 힌튼 교수는 렐루(ReLU)라는 새로운 활성화 함수를 제안\n",
    "    + 하이퍼볼릭 탄젠트(hyperbolic tangent)나 소프트플러스(softplus) 함수등 좀 더 나은 활성화 함수가 계속 만들어 지고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae8a8c-8b3a-45af-8565-73eb04d8c39b",
   "metadata": {},
   "source": [
    "## 경사하강법\n",
    "* 경사 하강법은 한 번 업데이트할 때마다 전체 데이터를 미분하므로 속도가 느릴 뿐 아니라, 최적 해를 찾기 전에 최적화 과정이 멈출 수도 있\n",
    "    + 확률적 경사 하강법(Stochastic Gradient Descent, SGD)은 경사 하강법의 이러한 단점을 보완한 방법    \n",
    "    + 전체 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터만 사용하기 때문에 빠르고 더 자주 업데이트할 수 있다는 장점\n",
    "    + 멘텀 확률적 경사 하강법(모멘텀 SGD)이란 말 그대로 경사 하강법에 탄력을 더해 주는 것\n",
    "    + adagrad, rmsprop, adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e1008-0b6a-4086-894e-d5879595eda9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
