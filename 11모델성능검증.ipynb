{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34ba6a1-2153-4fcc-8995-dea64b9dc670",
   "metadata": {},
   "source": [
    "## 모델 성능 검증\n",
    "* 1986년 제프리 힌튼 교수가 오차 역전파를 발표한 직후, \n",
    "* 존스 홉킨스의 세즈노프스키(Sejnowski) 교수는 오차 역전파가 은닉층의 가중치를 \n",
    "  실제로 업데이트시키는 것을 확인하고 싶었습니다. \n",
    "* 그는 광석과 일반 암석에 수중 음파 탐지기를 쏜 후 결과를 모아 데이터셋을 준비했고, \n",
    "* 음파 탐지기의 수신 결과만 보고 광석인지 일반 암석인지를 구분하는 모델을 만들\n",
    "* 세즈노프스키 교수가 했던 초음파 광물 예측 실험을 텐서플로로 재현해 보고, \n",
    "* 이렇게 구해진 실험 정확도를 평가하는 방법과 성능을 향상시키는 \n",
    "  중요한 머신 러닝 기법들에 대해 알아"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a86bad-54e0-4331-bbeb-82ae5c8f7fc3",
   "metadata": {},
   "source": [
    "## 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd98c2d-ca20-4926-8c03-1c274dc8c3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   0  \n",
       "1  0.0052  0.0044   0  \n",
       "2  0.0095  0.0078   0  \n",
       "3  0.0040  0.0117   0  \n",
       "4  0.0107  0.0094   0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas 라이브러리를 불러옵니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 광물 데이터를 불러옵니다.\n",
    "df = pd.read_csv('data/sonar3.csv', header=None)\n",
    "\n",
    "df.head() # 첫 다섯 줄을 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e27f901-b0a1-4960-a51f-89c55d0021e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    111\n",
       "0     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일반 암석과 광석이 각각 몇 개나 포함되어 있는지 알아\n",
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306bbad1-fda3-42c4-8f50-e87d6d23e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~60번째 열을 X 변수에 저장하고 광물의 종류는 y로 저장\n",
    "X = df.iloc[:,0:60]\n",
    "y = df.iloc[:,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d13ee-dcbb-4ace-a235-f2cf92fa0011",
   "metadata": {},
   "source": [
    "## 딥러닝 모델 생성 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3250a2ac-afe9-444d-8238-a90fcbc0907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Java\\miniconda3\\envs\\.py39\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 모델을 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2da5c25-51c2-4d0c-bef1-aefee9a41139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608cfe5a-f135-435b-befc-18e3172fd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 실행합니다.\n",
    "history = model.fit(X, y, epochs=200, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d79517d5-b622-41b9-91e0-7cf7284c6838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.485030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680813</td>\n",
       "      <td>0.574850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.669224</td>\n",
       "      <td>0.550898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657328</td>\n",
       "      <td>0.610778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645808</td>\n",
       "      <td>0.604790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy\n",
       "0  0.701026  0.485030\n",
       "1  0.680813  0.574850\n",
       "2  0.669224  0.550898\n",
       "3  0.657328  0.610778\n",
       "4  0.645808  0.604790"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dea36d-0bc0-4f7a-99b4-8a743fbea0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.995192289352417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 확인\n",
    "model.evaluate(X, y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f1df9-cb5f-4e2d-a721-a6c1eccec499",
   "metadata": {},
   "source": [
    "## 과적합 이해하기\n",
    "* 모델이 학습 데이터셋 안에서는 일정 수준 이상의 예측 정확도를 보이지만, \n",
    "* 새로운 데이터에 적용하면 잘 맞지 않는 것을 의미\n",
    "* 과적합은 층이 너무 많거나 변수가 복잡해서 발생하기도 하고 \n",
    "* 테스트셋과 학습셋이 중복될 때 생기기도 합니다. \n",
    "* 특히 딥러닝은 학습 단계에서 입력층, 은닉층, 출력층의 노드들에 상당히 많은 변수가 투입\n",
    "* 따라서 딥러닝을 진행하는 동안 과적합에 빠지지 않게 늘 주의해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861bde1-22d5-4779-9756-e62e739b8d36",
   "metadata": {},
   "source": [
    "## 학습셋과 테스트셋\n",
    "* 과적합을 방지하려면 먼저 학습을 하는 데이터셋과 \n",
    "* 이를 테스트할 데이터셋을 완전히 구분한 후 \n",
    "* 학습과 동시에 테스트를 병행하며 진행하는 것이 한 방법\n",
    "* 예를 들어 데이터셋이 총 100개의 샘플로 이루어져 있다면\n",
    "    + 신경망을 만들어 70개의 샘플로 학습을 진행한 후 이 학습의 결과를 저장\n",
    "    + 나머지 30개의 샘플로 실험해서 정확도를 살펴보면 \n",
    "    + 학습이 얼마나 잘되었는지 알 수 있는 것\n",
    "* 머신 러닝의 최종 목적은 과거의 데이터를 토대로 새로운 데이터를 예측하는 것입니다. \n",
    "* 즉, 새로운 데이터에 사용할 모델을 만드는 것이 최종 목적이므로 \n",
    "* 테스트셋을 만들어 정확한 평가를 병행하는 것이 매우 중요합니다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e856cb6-e3cc-4855-ac0d-e264f38afd31",
   "metadata": {},
   "source": [
    "* 초음파 광물 예측 데이터를 만든 세즈노프스키 교수가 실험 결과를 발표한 논문의 일부\n",
    "* 은닉층(Number of Hidden Units) 개수가 올라감에 따라 \n",
    "* 학습셋의 예측률(Average Performance on Training Sets)과 \n",
    "* 테스트셋의 예측률(Average Performance on Testing Sets)이 어떻게 변하는지\n",
    "    + 은닉층이 늘어날수록 학습셋의 예측률이 점점 올라가다가 \n",
    "    + 결국 24개의 층에 이르면 100% 예측률을 보입니\n",
    "* 딥러닝, 머신 러닝의 목표는 학습셋에서만 잘 작동하는 모델을 만드는 것이 아닙니다. \n",
    "* 새로운 데이터에 대해 높은 정확도를 안정되게 보여 주는 모델을 만드는 것이 목표\n",
    "* 데이터를 이용해 성능을 향상시키려면 우선 충분한 데이터를 가져와 추가하면 됩니다. \n",
    "* 데이터를 추가하는 것 자체가 어렵거나 데이터 추가만으로는 성능에 한계가 있을 수 있\n",
    "    + 따라서 가지고 있는 데이터를 적절히 보완해 주는 방법을 사용\n",
    "    + 교차 검증 방법을 사용해 가지고 있는 데이터를 충분히 이용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e6753-2570-4efa-ba4b-f4e901be815a",
   "metadata": {},
   "source": [
    "## 학습셋과 테스트셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160e6bdc-436d-414e-9346-ed12613463c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\lg pc\\appdata\\roaming\\python\\python39\\site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e8c7c8-116d-4687-9084-e875b3240451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습셋과 테스트셋을 구분합니다.\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e64fd0-ad24-4925-85f4-8664253b23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 다시 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c300350-af5b-4422-b828-174247b7959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9c58cd-d699-410e-8916-439ea2c325ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 실행합니다.\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "258486e3-4e25-4cb6-9704-457941361575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.8571\n",
      "Test accuracy: 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091f2eb-735f-4c40-bf23-c326dd69ce80",
   "metadata": {},
   "source": [
    "## 모델 저장과 재사용\n",
    "* 학습이 끝난 후 지금 만든 모델을 저장하면 언제든 이를 불러와 다시 사용할 수\n",
    "* hdf5 파일 포맷은 주로 과학 기술 데이터 작업에서 사용되는데, \n",
    "  크고 복잡한 데이터를 저장하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aafb807c-39fe-48e9-a97a-68ec429759f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba3b4a96-8ed5-4061-88d8-5cc8a268f7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "105cc205-2c1b-44ab-b109-1a652ac9158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과를 저장하려면 model.save() 함수를 이용해 모델 이름을 적어 저장\n",
    "# 모델 이름과 저장할 위치를 함께 지정합니다.\n",
    "model.save('data/model/model10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a49437d7-0d6a-4e61-9ac9-438e27408562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "405ca411-db47-45b2-b696-3f6ff7b7b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 위해 조금 전 만든 모델을 메모리에서 삭제\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b3afcae-adc3-4c52-be71-ec43f9c8dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model() 함수를 사용해서 조금 전 저장한 모델을 불러옵니다.\n",
    "# 모델이 저장된 위치와 이름까지 적어 줍니다.\n",
    "model = load_model('./data/model/model10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d10985b-cee8-4876-90f3-9c270eac079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.8571\n",
      "Test accuracy: 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "# 불러온 모델을 테스트셋에 적용해 정확도를 구합니다.\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748af19e-e297-4be5-8c2a-8aedcaa0b4e7",
   "metadata": {},
   "source": [
    "## k겹 교차 검증\n",
    "* 데이터가 충분히 많아야 모델 성능도 향상\n",
    "* 실제 프로젝트에서는 데이터를 확보하는 것이 쉽지 않거나 많은 비용이 발생하는 경우도 있습\n",
    "* 가지고 있는 데이터를 십분 활용하는 것이 중요\n",
    "    + 특히 학습셋을 70%, 테스트셋을 30%로 설정할 경우 \n",
    "    + 30%의 테스트셋은 학습에 이용할 수 없다는 단점\n",
    "* k겹 교차 검증이란 데이터셋을 여러 개로 나누어 하나씩 테스트셋으로 사용하고 \n",
    "* 나머지를 모두 합해서 학습셋으로 사용하는 방법\n",
    "* 가지고 있는 데이터의 100%를 학습셋으로 사용할 수 있고, \n",
    "  또 동시에 테스트셋으로도 사용할 수 있습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb0c60b-dcb5-47d8-9a04-dfdd97fd3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 원하는 수만큼 나누어 각각 학습셋과 테스트셋으로 사용되게 하는 함수는 \n",
    "# 사이킷런 라이브러리의 KFold() 함수\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 몇 겹으로 나눌 것인지 정합니다.\n",
    "k = 5 \n",
    "\n",
    "# KFold 함수를 불러옵니다. 분할하기 전에 샘플이 치우치지 않도록 섞어 줍니다.\n",
    "kfold = KFold(n_splits=k, shuffle=True) \n",
    "\n",
    "# 정확도가 채워질 빈 리스트를 준비합니다.\n",
    "acc_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "278b63a5-cff4-4d7c-a5ea-71493a3fe8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelOne():\n",
    "    model = Sequential() # 딥러닝 모델의 구조를 시작합니다.\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6c8885b-061e-465d-9f1f-cc7e49f8ac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.9048\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x000002012E2F2C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9980 - accuracy: 0.8095\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000002012F47B160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.8810\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.6829\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "# k겹 교차 검증을 이용해 k번의 학습을 실행합니다.\n",
    "# for 문에 의해 k번 반복합니다.\n",
    "# split()에 의해 k개의 학습셋, 테스트셋으로 분리됩니다.\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]  \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = modelOne()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0) \n",
    "    \n",
    "    accuracy = model.evaluate(X_test, y_test)[1] # 정확도를 구합니다.\n",
    "    acc_score.append(accuracy)                   # 정확도 리스트에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63979f71-a1de-4f2c-94fe-128a4a948e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  [0.9047619104385376, 0.8095238208770752, 0.8809523582458496, 0.6829268336296082, 0.8536585569381714]\n",
      "정확도 평균:  0.8263646960258484\n"
     ]
    }
   ],
   "source": [
    "# k번 실시된 정확도의 평균을 구합니다.\n",
    "avg_acc_score = sum(acc_score) / k\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print('정확도: ', acc_score)\n",
    "print('정확도 평균: ', avg_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc89811-4a99-435e-a844-968f37083834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
